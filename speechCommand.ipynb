{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sounddevice\n",
        "!pip install pydub"
      ],
      "metadata": {
        "id": "rN-c02OEVcEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnAHx2Y5xue3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "#import sounddevice as sd\n",
        "import scipy.signal\n",
        "import time\n",
        "\n",
        "import IPython\n",
        "import random\n",
        "from collections import deque, namedtuple\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ds_cnn(input_shape, num_classes):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(64, (10, 4), padding='same', activation='relu')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.DepthwiseConv2D((3, 3), padding='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Conv2D(64, (1, 1), activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "3oVoJb6BxxOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess audio files from training dataset, not audio recording\n",
        "def preprocess(audio, label):\n",
        "    audio = tf.cast(audio, tf.float32) / 32768.0\n",
        "    audio = tf.reshape(audio, [-1])\n",
        "    audio = audio[:16000]\n",
        "    zero_padding = tf.zeros([16000] - tf.shape(audio), dtype=tf.float32)\n",
        "    audio = tf.concat([audio, zero_padding], 0)\n",
        "\n",
        "    stft = tf.signal.stft(audio, frame_length=640, frame_step=320, fft_length=1024)\n",
        "    spectrogram = tf.abs(stft)\n",
        "    num_mel_bins = 40\n",
        "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "        num_mel_bins, spectrogram.shape[-1], 16000, 20.0, 4000.0)\n",
        "    mel_spectrogram = tf.tensordot(spectrogram, linear_to_mel_weight_matrix, 1)\n",
        "    mel_spectrogram.set_shape(spectrogram.shape[:-1].concatenate([num_mel_bins]))\n",
        "\n",
        "    log_mel_spectrogram = tf.math.log(mel_spectrogram + 1e-6)\n",
        "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)[..., :10]\n",
        "    mfccs = tf.ensure_shape(mfccs, [49, 10])\n",
        "    mfccs = tf.expand_dims(mfccs, -1)\n",
        "\n",
        "    label = tf.cast(label, tf.int64)\n",
        "    label = tf.ensure_shape(label, [])\n",
        "    return mfccs, label"
      ],
      "metadata": {
        "id": "m377HaHIx6Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    ds_train, ds_test = tfds.load(\n",
        "        'speech_commands',\n",
        "        split=['train[:5%]', 'train[5%:6%]'],  # small slice for demo\n",
        "        as_supervised=True,\n",
        "        with_info=False\n",
        "    )\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    ds_train = ds_train.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "    ds_train = ds_train.batch(32, drop_remainder=True).cache().prefetch(AUTOTUNE)\n",
        "    ds_test = ds_test.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "    ds_test = ds_test.batch(32, drop_remainder=True).cache().prefetch(AUTOTUNE)\n",
        "    return ds_train, ds_test"
      ],
      "metadata": {
        "id": "iwhtmPV_x69T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    ds_train, ds_test = load_dataset()\n",
        "    for _, y in ds_train.take(1):\n",
        "        num_classes = int(tf.reduce_max(y).numpy()) + 1\n",
        "\n",
        "    model = ds_cnn((49, 10, 1), num_classes)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    model.fit(ds_train, validation_data=ds_test, epochs=5)\n",
        "    model.save(\"kws_ds_cnn.h5\")\n",
        "\n",
        "    # Convert to TFLite\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite_model = converter.convert()\n",
        "    with open(\"kws_ds_cnn.tflite\", \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "    print(\"Saved kws_ds_cnn.tflite\")"
      ],
      "metadata": {
        "id": "pAlLmhoSx95t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "metadata": {
        "id": "MXByth6ByCXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_RATE = 16000\n",
        "RECORD_SECONDS = 1\n",
        "NUM_MFCC = 10\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=\"kws_ds_cnn.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ],
      "metadata": {
        "id": "P0C1ryMuWFpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record_audio():\n",
        "    print(\"Recording...\")\n",
        "    audio = sd.rec(int(SAMPLE_RATE * RECORD_SECONDS), samplerate=SAMPLE_RATE, channels=1, dtype='float32')\n",
        "    sd.wait()\n",
        "    print(\"Recording done.\")\n",
        "    return audio.flatten()"
      ],
      "metadata": {
        "id": "80MC2e2vWgvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pydub\n",
        "from IPython.display import Javascript, Audio\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "from io import BytesIO\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "def colab_record(sec = 5):\n",
        "  sec += 2\n",
        "  print('Begining Recording')\n",
        "  display(Javascript(RECORD))\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  print('Done!')\n",
        "  # convert to numpy array\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  audio = pydub.AudioSegment.from_file(BytesIO(b))\n",
        "  audio = np.asarray(audio.get_array_of_samples(), dtype='float32')\n",
        "  # calculate sample rate\n",
        "  rate = audio.size / sec\n",
        "  # remove the zeros at the begining of the recording\n",
        "  audio = np.trim_zeros(audio)\n",
        "  return audio.flatten(), rate"
      ],
      "metadata": {
        "id": "HZKtxkJJsMRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess audio from mic for inference! no training!\n",
        "def preprocess_audio(audio):\n",
        "    # Pad or truncate to 16000 samples\n",
        "    if len(audio) < SAMPLE_RATE:\n",
        "        audio = np.pad(audio, (0, SAMPLE_RATE - len(audio)), mode='constant')\n",
        "    else:\n",
        "        audio = audio[:SAMPLE_RATE]\n",
        "\n",
        "    stft = tf.signal.stft(audio, frame_length=640, frame_step=320, fft_length=1024)\n",
        "    spectrogram = tf.abs(stft)\n",
        "\n",
        "    mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "        num_mel_bins=40,\n",
        "        num_spectrogram_bins=stft.shape[-1],\n",
        "        sample_rate=SAMPLE_RATE,\n",
        "        lower_edge_hertz=20.0,\n",
        "        upper_edge_hertz=4000.0\n",
        "    )\n",
        "\n",
        "    mel_spectrogram = tf.tensordot(spectrogram, mel_weight_matrix, 1)\n",
        "    log_mel_spectrogram = tf.math.log(mel_spectrogram + 1e-6)\n",
        "\n",
        "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)[..., :NUM_MFCC]\n",
        "    mfccs = mfccs.numpy()\n",
        "\n",
        "    mfccs = mfccs[:49]  # Trim or pad time axis\n",
        "    if mfccs.shape[0] < 49:\n",
        "        mfccs = np.pad(mfccs, ((0, 49 - mfccs.shape[0]), (0, 0)), mode='constant')\n",
        "\n",
        "    mfccs = mfccs.reshape(1, 49, NUM_MFCC, 1).astype(np.float32)\n",
        "    return mfccs"
      ],
      "metadata": {
        "id": "Ly8QzVVRX0Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(mfccs):\n",
        "    interpreter.set_tensor(input_details[0]['index'], mfccs)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    prediction = np.argmax(output)\n",
        "    confidence = np.max(output)\n",
        "    return prediction, confidence"
      ],
      "metadata": {
        "id": "e8WdrniQYX3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Maze Logic\n",
        "Edge = tuple\n",
        "Tree = set\n",
        "Maze = namedtuple('Maze', 'width, height, edges')\n",
        "Square = tuple\n",
        "\n",
        "def edge(A, B) -> Edge: return Edge(sorted([A, B]))\n",
        "\n",
        "def random_tree(nodes, neighbors, pop=deque.pop) -> Tree:\n",
        "    \"\"\"Repeat: pop a node and add edge(node, nbr) until all nodes have been added to tree.\"\"\"\n",
        "    tree = Tree()\n",
        "    nodes = set(nodes)\n",
        "    root = nodes.pop()\n",
        "    frontier = deque([root])\n",
        "    while nodes:\n",
        "        node = pop(frontier)\n",
        "        nbrs = neighbors(node) & nodes\n",
        "        if nbrs:\n",
        "            nbr = random.choice(list(nbrs))\n",
        "            tree.add(edge(node, nbr))\n",
        "            nodes.remove(nbr)\n",
        "            frontier.extend([node, nbr])\n",
        "    return tree\n",
        "\n",
        "def neighbors4(square) -> {Square}:\n",
        "    \"\"\"The 4 neighbors of an (x, y) square.\"\"\"\n",
        "    (x, y) = square\n",
        "    return {(x + 1, y), (x - 1, y), (x, y + 1), (x, y - 1)}\n",
        "\n",
        "def grid(width, height) -> {Square}:\n",
        "    \"\"\"All squares in a grid of these dimensions.\"\"\"\n",
        "    return {(x, y) for x in range(width) for y in range(height)}\n",
        "\n",
        "def random_maze(width, height, pop=deque.pop) -> Maze:\n",
        "    \"\"\"Generate a random maze, using random_tree.\"\"\"\n",
        "    tree = random_tree(grid(width, height), neighbors4, pop)\n",
        "    return Maze(width, height, tree)\n",
        "\n",
        "def transpose(matrix): return list(zip(*matrix))\n",
        "\n",
        "def plot_wall(s1, s2):\n",
        "    \"\"\"Plot a wall: a black line between squares s1 and s2.\"\"\"\n",
        "    (x1, y1), (x2, y2) = s1, s2\n",
        "    if x1 == x2: # horizontal wall\n",
        "        y = max(y1, y2)\n",
        "        X, Y = [x1, x1+1], [y, y]\n",
        "    else: # vertical wall\n",
        "        x = max(x1, x2)\n",
        "        X, Y = [x, x], [y1, y1+1]\n",
        "    plt.plot(X, Y, 'k-', linewidth=2)\n",
        "\n",
        "def plot_maze(maze, figsize=None, path=None):\n",
        "    \"\"\"Plot a maze by drawing lines between adjacent squares, except for pairs in maze.edges\"\"\"\n",
        "    w, h  = maze.width, maze.height\n",
        "    plt.figure(figsize=figsize or (w/5, h/5))\n",
        "    plt.axis('off')\n",
        "    plt.gca().invert_yaxis()\n",
        "    exits = {edge((0, 0), (0, -1)), edge((w-1, h-1), (w-1, h))}\n",
        "    edges = maze.edges | exits\n",
        "    for sq in grid(w, h):\n",
        "        for nbr in neighbors4(sq):\n",
        "            if edge(sq, nbr) not in edges:\n",
        "                plot_wall(sq, nbr)\n",
        "    if path: # Plot the solution (or any path) as a red line through the maze\n",
        "        X, Y = transpose((x + 0.5, y + 0.5) for (x, y) in path)\n",
        "        plt.plot(X, Y, 'r-', linewidth=2)\n",
        "\n",
        "def show_game(M, player):\n",
        "  plot_maze(M, figsize=(6, 6))\n",
        "  player.plot()\n",
        "  plt.show()\n",
        "\n",
        "def check_move(move):\n",
        "  current_x, current_y = player.position\n",
        "  new_position = player.position\n",
        "\n",
        "  if move.lower() == 'right':\n",
        "      new_position = (current_x + 1, current_y)\n",
        "  elif move.lower() == 'left':\n",
        "      new_position = (current_x - 1, current_y)\n",
        "  elif move.lower() == 'up':\n",
        "      new_position = (current_x, current_y - 1)\n",
        "  elif move.lower() == 'down':\n",
        "      new_position = (current_x, current_y + 1)\n",
        "\n",
        "  return new_position"
      ],
      "metadata": {
        "id": "FSI8rBdLyiAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Player Class\n",
        "class Player: #position of 9, 9 signifies the end\n",
        "    def __init__(self, maze, start_position=(0, 0)):\n",
        "        self.maze = maze\n",
        "        self.position = start_position\n",
        "\n",
        "    def move(self, new_position):\n",
        "        if new_position in neighbors4(self.position):\n",
        "            # Check if the new position is within the maze boundaries\n",
        "            if 0 <= new_position[0] < self.maze.width and 0 <= new_position[1] < self.maze.height:\n",
        "                # Check if there's a wall between the current and new positions\n",
        "                if edge(self.position, new_position) in self.maze.edges:\n",
        "                    self.position = new_position\n",
        "\n",
        "    def plot(self):\n",
        "        x, y = self.position\n",
        "        plt.plot(x + 0.5, y + 0.5, 'bo', markersize=10)  # Blue circle"
      ],
      "metadata": {
        "id": "Ff-xh-sF1uDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Maze and Player\n",
        "M = random_maze(5, 5)\n",
        "player = Player(M)"
      ],
      "metadata": {
        "id": "kVF4Gnml0N8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence']\n",
        "\n",
        "while True:\n",
        "    show_game(M, player) #game\n",
        "    audio, rate = colab_record(1)\n",
        "    mfccs = preprocess_audio(audio)\n",
        "    pred, conf = run_inference(mfccs)\n",
        "    new_position = check_move(labels[pred]) #game\n",
        "    player.move(new_position) #game\n",
        "    print(f\"Prediction: {labels[pred]} (Confidence: {conf:.2f})\")\n",
        "    display(Audio(data=audio, rate=rate))\n",
        "    #input()\n",
        "    IPython.display.clear_output(wait=True) #game\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "id": "fMIocQB5Ybrv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}